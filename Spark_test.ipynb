{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM61n1ElWPxzXAhIDXOmfF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rbzkaf/Data-Science-Projects/blob/main/Spark_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jx_Jpl0Z2uE",
        "outputId": "78fc3a6b-cc7c-4436-bec2-616752e364b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 33 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 53.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=8e965294c07bcf54efa5d44a1aa1f904185cda1d8d11f02d2da0ae695fee5cda\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k83J-D32ZvHc"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName('Titanic Data') \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = (spark.read\n",
        "          .format(\"csv\")\n",
        "          .option('header', 'true')\n",
        "          .load(\"train.csv\"))"
      ],
      "metadata": {
        "id": "i-h5GuxEak_q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.toPandas()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrjrIM-hbBBs",
        "outputId": "0c289e91-2256-4509-fedc-d7fd5472fbc1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(PassengerId='1', Survived='0', Pclass='3', Name='Braund, Mr. Owen Harris', Sex='male', Age='22', SibSp='1', Parch='0', Ticket='A/5 21171', Fare='7.25', Cabin=None, Embarked='S')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "dataset = df.select(col('Survived').cast('float'),\n",
        "                         col('Pclass').cast('float'),\n",
        "                         col('Sex'),\n",
        "                         col('Age').cast('float'),\n",
        "                         col('Fare').cast('float'),\n",
        "                         col('Embarked')\n",
        "                        )\n",
        "dataset.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bXrw9V3bH5N",
        "outputId": "90d35263-04af-41f0-ee23-d459c4417474"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-------+--------+\n",
            "|Survived|Pclass|   Sex| Age|   Fare|Embarked|\n",
            "+--------+------+------+----+-------+--------+\n",
            "|     0.0|   3.0|  male|22.0|   7.25|       S|\n",
            "|     1.0|   1.0|female|38.0|71.2833|       C|\n",
            "|     1.0|   3.0|female|26.0|  7.925|       S|\n",
            "|     1.0|   1.0|female|35.0|   53.1|       S|\n",
            "|     0.0|   3.0|  male|35.0|   8.05|       S|\n",
            "|     0.0|   3.0|  male|null| 8.4583|       Q|\n",
            "|     0.0|   1.0|  male|54.0|51.8625|       S|\n",
            "|     0.0|   3.0|  male| 2.0| 21.075|       S|\n",
            "|     1.0|   3.0|female|27.0|11.1333|       S|\n",
            "|     1.0|   2.0|female|14.0|30.0708|       C|\n",
            "|     1.0|   3.0|female| 4.0|   16.7|       S|\n",
            "|     1.0|   1.0|female|58.0|  26.55|       S|\n",
            "|     0.0|   3.0|  male|20.0|   8.05|       S|\n",
            "|     0.0|   3.0|  male|39.0| 31.275|       S|\n",
            "|     0.0|   3.0|female|14.0| 7.8542|       S|\n",
            "|     1.0|   2.0|female|55.0|   16.0|       S|\n",
            "|     0.0|   3.0|  male| 2.0| 29.125|       Q|\n",
            "|     1.0|   2.0|  male|null|   13.0|       S|\n",
            "|     0.0|   3.0|female|31.0|   18.0|       S|\n",
            "|     1.0|   3.0|female|null|  7.225|       C|\n",
            "+--------+------+------+----+-------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.replace('?', None).dropna(how='any')"
      ],
      "metadata": {
        "id": "lXIOHCpUbSq4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "dataset = StringIndexer(\n",
        "    inputCol='Sex', \n",
        "    outputCol='Gender', \n",
        "    handleInvalid='keep').fit(dataset).transform(dataset)\n",
        "dataset = StringIndexer(\n",
        "    inputCol='Embarked', \n",
        "    outputCol='Boarded', \n",
        "    handleInvalid='keep').fit(dataset).transform(dataset)\n",
        "dataset.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orb3xVaVbs4W",
        "outputId": "3de12168-ca44-46f5-d934-9cc26ae84baf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-------+--------+------+-------+\n",
            "|Survived|Pclass|   Sex| Age|   Fare|Embarked|Gender|Boarded|\n",
            "+--------+------+------+----+-------+--------+------+-------+\n",
            "|     0.0|   3.0|  male|22.0|   7.25|       S|   0.0|    0.0|\n",
            "|     1.0|   1.0|female|38.0|71.2833|       C|   1.0|    1.0|\n",
            "|     1.0|   3.0|female|26.0|  7.925|       S|   1.0|    0.0|\n",
            "|     1.0|   1.0|female|35.0|   53.1|       S|   1.0|    0.0|\n",
            "|     0.0|   3.0|  male|35.0|   8.05|       S|   0.0|    0.0|\n",
            "|     0.0|   1.0|  male|54.0|51.8625|       S|   0.0|    0.0|\n",
            "|     0.0|   3.0|  male| 2.0| 21.075|       S|   0.0|    0.0|\n",
            "|     1.0|   3.0|female|27.0|11.1333|       S|   1.0|    0.0|\n",
            "|     1.0|   2.0|female|14.0|30.0708|       C|   1.0|    1.0|\n",
            "|     1.0|   3.0|female| 4.0|   16.7|       S|   1.0|    0.0|\n",
            "|     1.0|   1.0|female|58.0|  26.55|       S|   1.0|    0.0|\n",
            "|     0.0|   3.0|  male|20.0|   8.05|       S|   0.0|    0.0|\n",
            "|     0.0|   3.0|  male|39.0| 31.275|       S|   0.0|    0.0|\n",
            "|     0.0|   3.0|female|14.0| 7.8542|       S|   1.0|    0.0|\n",
            "|     1.0|   2.0|female|55.0|   16.0|       S|   1.0|    0.0|\n",
            "|     0.0|   3.0|  male| 2.0| 29.125|       Q|   0.0|    2.0|\n",
            "|     0.0|   3.0|female|31.0|   18.0|       S|   1.0|    0.0|\n",
            "|     0.0|   2.0|  male|35.0|   26.0|       S|   0.0|    0.0|\n",
            "|     1.0|   2.0|  male|34.0|   13.0|       S|   0.0|    0.0|\n",
            "|     1.0|   3.0|female|15.0| 8.0292|       Q|   1.0|    2.0|\n",
            "+--------+------+------+----+-------+--------+------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.drop('Sex')\n",
        "dataset = dataset.drop('Embarked')\n",
        "dataset.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR7F1L_Bbvuw",
        "outputId": "5a1c390f-dc81-4f9c-e698-facfd3f4cc7f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+----+-------+------+-------+\n",
            "|Survived|Pclass| Age|   Fare|Gender|Boarded|\n",
            "+--------+------+----+-------+------+-------+\n",
            "|     0.0|   3.0|22.0|   7.25|   0.0|    0.0|\n",
            "|     1.0|   1.0|38.0|71.2833|   1.0|    1.0|\n",
            "|     1.0|   3.0|26.0|  7.925|   1.0|    0.0|\n",
            "|     1.0|   1.0|35.0|   53.1|   1.0|    0.0|\n",
            "|     0.0|   3.0|35.0|   8.05|   0.0|    0.0|\n",
            "|     0.0|   1.0|54.0|51.8625|   0.0|    0.0|\n",
            "|     0.0|   3.0| 2.0| 21.075|   0.0|    0.0|\n",
            "|     1.0|   3.0|27.0|11.1333|   1.0|    0.0|\n",
            "|     1.0|   2.0|14.0|30.0708|   1.0|    1.0|\n",
            "|     1.0|   3.0| 4.0|   16.7|   1.0|    0.0|\n",
            "|     1.0|   1.0|58.0|  26.55|   1.0|    0.0|\n",
            "|     0.0|   3.0|20.0|   8.05|   0.0|    0.0|\n",
            "|     0.0|   3.0|39.0| 31.275|   0.0|    0.0|\n",
            "|     0.0|   3.0|14.0| 7.8542|   1.0|    0.0|\n",
            "|     1.0|   2.0|55.0|   16.0|   1.0|    0.0|\n",
            "|     0.0|   3.0| 2.0| 29.125|   0.0|    2.0|\n",
            "|     0.0|   3.0|31.0|   18.0|   1.0|    0.0|\n",
            "|     0.0|   2.0|35.0|   26.0|   0.0|    0.0|\n",
            "|     1.0|   2.0|34.0|   13.0|   0.0|    0.0|\n",
            "|     1.0|   3.0|15.0| 8.0292|   1.0|    2.0|\n",
            "+--------+------+----+-------+------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "required_features = ['Pclass',\n",
        "                    'Age',\n",
        "                    'Fare',\n",
        "                    'Gender',\n",
        "                    'Boarded'\n",
        "                   ]\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=required_features, outputCol='features')\n",
        "transformed_data = assembler.transform(dataset)"
      ],
      "metadata": {
        "id": "8XkK_HQCbW0o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(training_data, test_data) = transformed_data.randomSplit([0.8,0.2])"
      ],
      "metadata": {
        "id": "GHe0hKdgb4XG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(labelCol='Survived', \n",
        "                            featuresCol='features',\n",
        "                            maxDepth=4)"
      ],
      "metadata": {
        "id": "nq0bxf99b6L4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = rf.fit(training_data)"
      ],
      "metadata": {
        "id": "Dgx_vYanb72z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)"
      ],
      "metadata": {
        "id": "Jh7qH6Cnb8O4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol='Survived', \n",
        "    predictionCol='prediction', \n",
        "    metricName='accuracy')\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print('Test Accuracy = ', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY9MF4KbcBvZ",
        "outputId": "a535d6d6-3bad-4734-8c5a-0f48c7d88a87"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy =  0.8104575163398693\n"
          ]
        }
      ]
    }
  ]
}